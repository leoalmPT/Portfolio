## Overview

[Repository](https://github.com/AIDetx/AIDetx) - [Paper](/files/papers/dcc2025/paper.pdf) - [DOI](https://doi.org/10.1109/dcc62719.2025.00046)

This paper presents [AIDetx](TODO), a novel and computationally efficient approach for distinguishing between human-written and AI-generated text. It offers a more interpretable alternative to traditional deep learning methods.

## About the Paper

The rapid advancement of AI has led to a proliferation of AI-generated content, raising concerns about its potential misuse, such as spreading misinformation. Current methods for detecting AI-generated text, often based on deep learning, suffer from high computational costs, limited interpretability, and the need for substantial input text.

Our work introduces **AIDetx**, a compression-based classification framework that addresses these limitations using **finite-context models (FCMs)**. Key aspects include:

-   **Compression-based classification:** AIDetx builds distinct compression models for human-written and AI-generated text. New inputs are classified based on which model achieves a higher compression ratio, effectively "training" classifiers on labeled documents.
-   **Finite-context models (FCMs):** These probabilistic models, relying on the Markov property, determine the number of bits required to encode symbols within specific contexts, providing a robust mechanism for text analysis.
-   **Computational efficiency:** Unlike deep learning models, AIDetx significantly reduces training time and hardware requirements, notably **requiring no GPUs**. It achieves impressive inference speeds, handling around **3.1 million characters per second using only a single CPU core** for the HC3 dataset and 2.95 million for the AI-human-text dataset, indicating strong performance even without parallel computing.
-   **Interpretability:** The compression-based approach offers greater transparency compared to complex neural networks.
-   **Experimental validation:** Evaluated on two benchmark datasets (HC3 and AI-human-text), AIDetx achieved F1 scores exceeding **97% and 99%**, respectively, demonstrating high accuracy. The study also optimized hyperparameters (*k* for Markov model order, *α* for smoothing factor, and *Σ* for alphabet) and assessed the influence of reference text length and target text size on performance.

The results highlight AIDetx's potential as an accurate, efficient, and interpretable solution for identifying machine-generated text, especially in scenarios with limited computational resources.

### Overview of the classifier based on finite-context models (FCMs).

<img src="/files/papers/dcc2025/overview.png" alt="Classifier Overview" width="600" />

### F1 score for the grid search of hyperparameters *k* and *α*.

<img src="/files/papers/dcc2025/tuning.png" alt="Hyperparameter Tunning F1 Score" width="1000" />


### Confusion matrix for HC3 and AI-human-text test datasets.

<img src="/files/papers/dcc2025/matrix.png" alt="Confusion Matrix" width="1000" />

## Final Thoughts

This work demonstrates that data compression techniques, specifically finite-context models, can provide a **highly effective, computationally efficient, and interpretable alternative** for detecting AI-generated text. AIDetx proves that high accuracy is achievable even without the heavy computational demands of deep learning, making it a viable solution for resource-constrained environments and applications where transparency is crucial.