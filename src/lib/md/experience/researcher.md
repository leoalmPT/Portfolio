## Overview

During my two-year research experience, supported by a [**Research Grant**](/recognition/researchgrant2023) alongside my [Master’s](/recognition/masters) studies, I specialized in Machine Learning and DevOps, particularly focusing on Federated Learning (FL) and its applications in dynamic, resource-constrained environments like 5G, 6G, and IoT. This period was marked by significant contributions to both research and academic mentorship.

## Key Contributions & Responsibilities:

*   **Federated Learning Framework Development:** I was the primary developer of [**FlexFL**](TODO), a modular and resilient Federated Learning framework (the subject of my Master's dissertation). This involved designing its architecture, implementing core FL logic, integrating various communication protocols (e.g., Zenoh, MQTT, Kafka), and ensuring fault tolerance and elasticity in distributed settings.
*   **Experimental Design & Execution:** I designed and configured multi-VM environment using Proxmox to run distributed FL experiments across numerous workers. I ran multiple complex experiments to gather comprehensive results, evaluating framework performance, communication overheads, and resilience under various failure scenarios.
*   **Data Engineering & Analysis:** My work involved preprocessing multiple complex datasets, ensuring their suitability for ML models and FL experiments, while also conducting extensive State-of-the-Art (SOA) analyses to inform research directions and identify key challenges in distributed ML and XAI.
*   **Research Output:** These efforts culminated in contributions to **9 published papers**, disseminating novel findings on resilient FL, efficient AI for next-generation networks, and explainable AI.
*   **Academic Mentorship:** I assisted in the supervision of a final project for the LECI Bachelor’s degree as part of the PECI subject. The project aimed to develop a robust management tool for FL, focusing on simplifying the training process by providing a user-friendly interface. The project's initial codebase was an adaptation of my own Master's thesis work, providing a direct link between my research and student development. My role involved guiding the team through project phases, from analyzing existing FL platform limitations (API support, monitoring tools) to defining and implementing new APIs, developing a web-based management framework, and planning its validation and documentation.

## Scientific Contributions:

- [Federated Learning for a Dynamic Edge: A Modular and Resilient Approach](/papers/sensors2025)
- [Efficient training: Federated learning cost analysis](/papers/bigdata2025)
- [AIDetx: A Compression-Based Method for Identification of Machine-Learning Generated Text](/papers/dcc2025)
- [From Black Box to Transparency: Consistency and Cost within XAI](/papers/globecom2024)
- [Shallow vs. Deep Learning: Prioritizing Efficiency in Next Generation Networks](/papers/ficloud2024)
- [Privacy-Preserving Defense: Intrusion Detection in IoT using Federated Learning](/papers/melecon2024)
- [Resilient Federated Learning Framework for 6G](/papers/icctfl2025)
- [Optimised Task Placement for MLOps](/papers/icctmlops2025)
- [Understanding What Federated Learning Models Learn: a Comparative Study with Traditional Models](/papers/wimob2025)

## Final Thoughts

This experience provided me with a strong foundation in distributed machine learning, experimental methodology, and a practical understanding of bridging research concepts with real-world applications and educational guidance. My hands-on involvement in configuring virtualized environments, deploying complex distributed systems, and setting up publish/subscribe communication protocols also equipped me with valuable skills essential for managing and scaling modern infrastructures.